import os
import ray
import gymnasium as gym
import numpy as np
import imageio
from ray.rllib.algorithms.algorithm import Algorithm
from ray.rllib.models import ModelCatalog
from ray.tune.registry import register_env
from pettingzoo.utils.wrappers import BaseParallelWrapper
from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv
from shimmy import MeltingPotCompatibilityV0
from shimmy.utils.meltingpot import load_meltingpot

# ì‚¬ìš©ì ëª¨ë¸ ì„í¬íŠ¸ (ì´ê±´ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤)
try:
    from model import MeltingPotModel
except ImportError:
    print("âŒ 'model.py' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ í´ë”ì— model.pyê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# ==============================================================================
# [ì„¤ì •] ê²½ë¡œ ë° íŒŒë¼ë¯¸í„° (ì—¬ê¸°ë¥¼ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)
# ==============================================================================
CHECKPOINT_PATH = "/home/jsr/project/Cooperative_pong_RL_agent/Meltingpot_muliagent_env/common_harvest_partnership/results/MeltingPot_Partnership_PPO_Final/PPO_meltingpot_partnership_complete_59211_00000_0_2026-02-04_12-48-20/checkpoint_000054"  # ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì…ë ¥
OUTPUT_VIDEO_PATH = "partnership_result.mp4"
MAX_STEPS = 1000
FPS = 10
SUBSTRATE_NAME = "commons_harvest__partnership" # (ì˜¤íƒ€ ìˆ˜ì •ë¨)

# ==============================================================================
# [í•µì‹¬] í™˜ê²½ ë˜í¼ í´ë˜ìŠ¤ ì§ì ‘ ì •ì˜ (env_utils.py ì˜ì¡´ì„± ì œê±°)
# ==============================================================================
class DirectRGBWrapper(BaseParallelWrapper):
    """ê´€ì¸¡ê°’ ë”•ì…”ë„ˆë¦¬ì—ì„œ 'RGB'ë§Œ ê°•ì œë¡œ ì¶”ì¶œí•˜ëŠ” ë˜í¼"""
    def __init__(self, env):
        super().__init__(env)
        self.observation_spaces = {}
        agents = getattr(env, "possible_agents", getattr(env, "agents", []))
        
        for agent in agents:
            obs_space = env.observation_space(agent)
            # Dict ê³µê°„ì´ë©´ RGBë§Œ ì¶”ì¶œí•´ì„œ Box ê³µê°„ìœ¼ë¡œ ë³€ê²½
            if isinstance(obs_space, gym.spaces.Dict):
                self.observation_spaces[agent] = obs_space["RGB"]
            else:
                self.observation_spaces[agent] = obs_space

    def observation_space(self, agent):
        return self.observation_spaces[agent]

    def reset(self, seed=None, options=None):
        obs, infos = self.env.reset(seed=seed, options=options)
        return self._process_obs(obs), infos

    def step(self, actions):
        obs, rewards, terminations, truncations, infos = self.env.step(actions)
        return self._process_obs(obs), rewards, terminations, truncations, infos

    def _process_obs(self, obs_dict):
        new_obs = {}
        for agent, data in obs_dict.items():
            # ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ê³  'RGB' í‚¤ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë§Œ êº¼ëƒ„
            if isinstance(data, dict) and "RGB" in data:
                new_obs[agent] = data["RGB"]
            else:
                new_obs[agent] = data
        return new_obs
    
    def render(self, *args, **kwargs):
        return self.env.render()

class RLlibCompatWrapper(ParallelPettingZooEnv):
    """RLlib í˜¸í™˜ì„± ë° ë Œë”ë§ ì¸ì ë¬¸ì œ í•´ê²°"""
    def __init__(self, env):
        super().__init__(env)
    
    def render(self, *args, **kwargs):
        return self.par_env.render()

# ==============================================================================
# [í•¨ìˆ˜] í™˜ê²½ ìƒì„± (ì§ì ‘ ì •ì˜í•œ ë˜í¼ ì‚¬ìš©)
# ==============================================================================
def local_env_creator(config=None):
    # 1. ë¡œë“œ
    substrate = load_meltingpot(SUBSTRATE_NAME)
    # 2. Shimmy ë³€í™˜
    env = MeltingPotCompatibilityV0(substrate, render_mode="rgb_array")
    # 3. [ì¤‘ìš”] RGB ì¶”ì¶œ (ì—¬ê¸°ì„œ Dict -> Array ë³€í™˜ë¨)
    env = DirectRGBWrapper(env)
    # 4. RLlib í˜¸í™˜
    env = RLlibCompatWrapper(env)
    return env

# ==============================================================================
# [í•¨ìˆ˜] ì •ì±… ë§¤í•‘
# ==============================================================================
def policy_mapping_fn(agent_id, *args, **kwargs):
    if agent_id in ["player_0", "player_1"]:
        return "shared_policy"
    else:
        return "background_policy"

# ==============================================================================
# [ë©”ì¸] ì‹¤í–‰ ë¡œì§
# ==============================================================================
def main():
    if ray.is_initialized():
        ray.shutdown()
    ray.init(ignore_reinit_error=True)

    # ëª¨ë¸ ë“±ë¡
    ModelCatalog.register_custom_model("meltingpot_model", MeltingPotModel)
    
    # í™˜ê²½ ë“±ë¡ (ìœ„ì—ì„œ ë§Œë“  í•¨ìˆ˜ ì‚¬ìš©)
    register_env("meltingpot_partnership_complete", lambda cfg: local_env_creator(cfg))

    print(f"ğŸ”„ Loading Checkpoint from: {CHECKPOINT_PATH}")
    
    try:
        algo = Algorithm.from_checkpoint(CHECKPOINT_PATH)
    except Exception as e:
        print(f"âŒ Checkpoint Load Error: {e}")
        return

    print("âœ… Model Loaded!")

    # ë Œë”ë§ìš© í™˜ê²½ ìƒì„±
    env = local_env_creator()
    
    obs, info = env.reset()
    
    # ë””ë²„ê¹…: ê´€ì¸¡ê°’ í˜•íƒœ í™•ì¸
    first_agent = list(obs.keys())[0]
    print(f"ğŸ” First observation type: {type(obs[first_agent])}")
    if isinstance(obs[first_agent], dict):
        print("âŒ Still getting a Dict! Wrapper failed.")
        print(f"   Keys: {obs[first_agent].keys()}")
        return
    else:
        print(f"âœ… Observation is Array! Shape: {obs[first_agent].shape}")

    # LSTM ìƒíƒœ ì´ˆê¸°í™”
    agent_states = {}
    shared_init = algo.get_policy("shared_policy").get_initial_state()
    bg_init = algo.get_policy("background_policy").get_initial_state()
    
    for agent_id in env.par_env.possible_agents:
        pid = policy_mapping_fn(agent_id)
        agent_states[agent_id] = shared_init if pid == "shared_policy" else bg_init

    print("ğŸ¬ Start Recording...")
    frames = []
    
    for step in range(MAX_STEPS):
        try:
            frame = env.render()
            if frame is not None:
                frames.append(frame)
        except Exception as e:
            print(f"Render Error: {e}")

        actions = {}
        for agent_id, agent_obs in obs.items():
            pid = policy_mapping_fn(agent_id)
            # RLlib ì¶”ë¡ 
            action, next_state, _ = algo.compute_single_action(
                observation=agent_obs,
                state=agent_states[agent_id],
                policy_id=pid,
                explore=False
            )
            actions[agent_id] = action
            agent_states[agent_id] = next_state

        obs, rewards, terms, truncs, infos = env.step(actions)
        
        if terms.get("__all__", False) or truncs.get("__all__", False):
            print(f"Done at step {step}")
            break

    env.close()
    
    if frames:
        print(f"ğŸ’¾ Saving {len(frames)} frames to {OUTPUT_VIDEO_PATH}...")
        imageio.mimsave(OUTPUT_VIDEO_PATH, frames, fps=FPS, macro_block_size=None)
        print("ğŸ‰ Success!")
    else:
        print("âŒ No frames captured.")

    ray.shutdown()

if __name__ == "__main__":
    main()
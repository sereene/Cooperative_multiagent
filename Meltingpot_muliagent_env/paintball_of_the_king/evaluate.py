import os
import cv2  # í™”ë©´ ë Œë”ë§ìš©
import numpy as np
import ray
from ray.rllib.algorithms.algorithm import Algorithm
from ray.rllib.models import ModelCatalog
from ray.tune.registry import register_env

# ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ì—ì„œ ëª¨ë“ˆ ì„í¬íŠ¸
from env_utils import env_creator
from model import MeltingPotModel

# ==============================================================================
# [ì„¤ì •] ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë° ì˜µì…˜
# ==============================================================================
# ì˜ˆ: "results_selfplay/MeltingPot_KOTH_.../checkpoint_000050"
# í´ë” ì•ˆì— 'algorithm_state.pkl' ë˜ëŠ” 'rllib_checkpoint.json' ë“±ì´ ë“¤ì–´ìˆëŠ” ê²½ë¡œì—¬ì•¼ í•©ë‹ˆë‹¤.
CHECKPOINT_PATH = "/home/jsr/project/Cooperative_pong_RL_agent/Meltingpot_muliagent_env/paintball_of_the_king/results_selfplay/MeltingPot_KOTH_SelfPlay_noBot_1e-5_Fc256/PPO_meltingpot_paintball_koth_mixed_70817_00000_0_2026-02-06_20-24-45/checkpoint_000193"

NUM_EPISODES = 5          # ì‹¤í–‰í•  ì—í”¼ì†Œë“œ ìˆ˜
RENDER_SCALE = 5          # í™”ë©´ í™•ëŒ€ ë°°ìœ¨ (MeltingPot ê¸°ë³¸ì´ ì‘ìœ¼ë¯€ë¡œ í™•ëŒ€ í•„ìš”)
FPS = 15                  # ë Œë”ë§ ì†ë„ (ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜)

# ì •ì±… ë§¤í•‘ í•¨ìˆ˜ (train.pyì™€ ë™ì¼í•˜ê²Œ ì„¤ì •)
def policy_mapping_fn(agent_id, *args, **kwargs):
    if agent_id in ["player_0", "player_2"]:  # Red Team
        return "main_policy"
    else:  # Blue Team (player_1, player_3)
        return "opponent_policy"

# ==============================================================================
# [ë©”ì¸] í‰ê°€ ë£¨í”„
# ==============================================================================
def run_evaluation():
    # 1. Ray ì´ˆê¸°í™” ë° ëª¨ë¸/í™˜ê²½ ë“±ë¡
    if not ray.is_initialized():
        ray.init(ignore_reinit_error=True)
    
    ModelCatalog.register_custom_model("meltingpot_model", MeltingPotModel)
    env_name = "meltingpot_paintball_koth_mixed"
    register_env(env_name, lambda cfg: env_creator({"substrate": "paintball__king_of_the_hill"}))

    print(f"ğŸ”„ Loading checkpoint from: {CHECKPOINT_PATH}")
    
    # 2. ì•Œê³ ë¦¬ì¦˜(ì²´í¬í¬ì¸íŠ¸) ë¡œë“œ
    try:
        algo = Algorithm.from_checkpoint(CHECKPOINT_PATH)
    except Exception as e:
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ê²½ë¡œê°€ ì •í™•í•œì§€, model.pyì™€ env_utils.pyê°€ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    # 3. í™˜ê²½ ìƒì„±
    # í•™ìŠµ ë•Œì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ê°€ í¬í•¨ëœ í™˜ê²½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    env = env_creator({"substrate": "paintball__king_of_the_hill"})

    # 4. ì—í”¼ì†Œë“œ ë£¨í”„
    for i in range(NUM_EPISODES):
        print(f"\nğŸ¬ Starting Episode {i+1}/{NUM_EPISODES}")
        
        obs, infos = env.reset()
        done = False
        
        # ì ìˆ˜ ì§‘ê³„ìš©
        episode_rewards = {agent_id: 0.0 for agent_id in env.par_env.possible_agents}
        step_count = 0

        # ì—ì´ì „íŠ¸ ë‚´ë¶€ ìƒíƒœ (ëª¨ë¸ì´ Statelessì—¬ë„ í˜•ì‹ìƒ í•„ìš”í•  ìˆ˜ ìˆìŒ)
        # model.pyë¥¼ ë³´ë‹ˆ ìƒíƒœê°€ ì—†ëŠ”(Stateless) ëª¨ë¸ì´ì§€ë§Œ, í˜¸í™˜ì„±ì„ ìœ„í•´ ê´€ë¦¬ êµ¬ì¡°ë§Œ ìœ ì§€
        agent_states = {} 

        while not done:
            # --- [ë Œë”ë§] ---
            # Shimmy í™˜ê²½ì€ par_env.render()ë¥¼ í†µí•´ RGB ì´ë¯¸ì§€ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            try:
                frame = env.par_env.render()
                if frame is not None:
                    # OpenCVëŠ” BGRì„ ì‚¬ìš©í•˜ë¯€ë¡œ RGB -> BGR ë³€í™˜
                    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    
                    # í™”ë©´ í™•ëŒ€
                    h, w, _ = frame_bgr.shape
                    frame_resized = cv2.resize(frame_bgr, (w * RENDER_SCALE, h * RENDER_SCALE), interpolation=cv2.INTER_NEAREST)
                    
                    # ì •ë³´ í…ìŠ¤íŠ¸ í‘œì‹œ
                    cv2.putText(frame_resized, f"Ep {i+1} | Step {step_count}", (10, 30), 
                                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                    
                    cv2.imshow("Melting Pot - Paintball KOTH", frame_resized)
                    
                    # í‚¤ ì…ë ¥ ëŒ€ê¸° (ESC ëˆ„ë¥´ë©´ ì¢…ë£Œ)
                    if cv2.waitKey(1000 // FPS) & 0xFF == 27:
                        print("User interrupted.")
                        env.close()
                        cv2.destroyAllWindows()
                        return
            except Exception as e:
                print(f"Rendering error: {e}")

            # --- [í–‰ë™ ê²°ì •] ---
            actions = {}
            for agent_id, agent_obs in obs.items():
                policy_id = policy_mapping_fn(agent_id)
                
                # ìƒíƒœ ì´ˆê¸°í™” (í•„ìš”ì‹œ)
                if agent_id not in agent_states:
                    policy = algo.get_policy(policy_id)
                    agent_states[agent_id] = policy.get_initial_state()

                # í–‰ë™ ê³„ì‚°
                # explore=Falseë¡œ ì„¤ì •í•˜ì—¬ ê²°ì •ë¡ ì (ìµœì ) í–‰ë™ì„ í•˜ë„ë¡ í•¨
                compute_result = algo.compute_single_action(
                    agent_obs,
                    state=agent_states[agent_id],
                    policy_id=policy_id,
                    explore=False, 
                    full_fetch=True
                )
                
                # ê²°ê³¼ ì–¸íŒ¨í‚¹ (callbacks.pyì˜ ë¡œì§ ì°¸ì¡°)
                if isinstance(compute_result, tuple) and len(compute_result) >= 3:
                    action, state_out, _ = compute_result
                else:
                    action = compute_result
                    state_out = agent_states[agent_id]
                
                actions[agent_id] = action
                agent_states[agent_id] = state_out

            # --- [ìŠ¤í… ì§„í–‰] ---
            obs, rewards, terminations, truncations, infos = env.step(actions)
            step_count += 1

            # ë¦¬ì›Œë“œ ëˆ„ì 
            for agent_id, reward in rewards.items():
                episode_rewards[agent_id] += reward

            # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
            if any(terminations.values()) or all(truncations.values()) or len(obs) == 0:
                done = True

        # --- [ì—í”¼ì†Œë“œ ê²°ê³¼ ì¶œë ¥] ---
        print(f"âœ… Episode {i+1} Finished ({step_count} steps)")
        print("   [Scores]")
        
        red_score = episode_rewards.get("player_0", 0) + episode_rewards.get("player_2", 0)
        blue_score = episode_rewards.get("player_1", 0) + episode_rewards.get("player_3", 0)
        
        for agent_id, score in episode_rewards.items():
            team = "(Red)" if agent_id in ["player_0", "player_2"] else "(Blue)"
            print(f"   - {agent_id} {team}: {score:.2f}")
        
        print(f"   ğŸ† Result: Red {red_score:.1f} vs Blue {blue_score:.1f}")
        print("-" * 40)

    # ì¢…ë£Œ ì²˜ë¦¬
    env.close()
    cv2.destroyAllWindows()
    ray.shutdown()
    print("All evaluation episodes completed.")

if __name__ == "__main__":
    run_evaluation()
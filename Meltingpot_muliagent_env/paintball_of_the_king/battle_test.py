import os
import sys
import collections
import cv2
import numpy as np
import ray
import dm_env
import shimmy
import torch

from ray.rllib.algorithms.algorithm import Algorithm
from ray.rllib.models import ModelCatalog
from ray.tune.registry import register_env

# [DeepMind Melting Pot Policy Import]
# ê²½ë¡œ ì„¤ì •ì´ í•„ìš”í•˜ë‹¤ë©´ sys.path.appendë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
try:
    from meltingpot.utils.policies import saved_model_policy
except ImportError:
    # ì˜ˆ: meltingpot_repoê°€ í˜„ì¬ í´ë”ì— ìˆë‹¤ë©´
    try:
        from meltingpot_repo.meltingpot.utils.policies import saved_model_policy
    except ImportError:
        print("âš ï¸ [Error] 'meltingpot' íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        sys.exit(1)

# [ì‚¬ìš©ì íŒŒì¼ Import] (env_utils.py, model.pyê°€ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨)
try:
    from env_utils import env_creator
    from model import MeltingPotModel
except ImportError:
    print("âŒ [Error] 'env_utils.py' ë˜ëŠ” 'model.py'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# ==============================================================================
# 1. ì„¤ì • (ê²½ë¡œ ë° íŒŒë¼ë¯¸í„°)
# ==============================================================================
# [User] í•™ìŠµëœ ì²´í¬í¬ì¸íŠ¸
USER_CHECKPOINT_PATH = "/home/jsr/project/Cooperative_pong_RL_agent/Meltingpot_muliagent_env/paintball_of_the_king/results_selfplay/MeltingPot_KOTH_SelfPlay_noBot_1e-5_Fc256/PPO_meltingpot_paintball_koth_mixed_70817_00000_0_2026-02-06_20-24-45/checkpoint_000195"

# [Bot] ë°°ê²½ ë´‡ SavedModel
BOT_MODEL_DIR = "/home/jsr/project/Cooperative_pong_RL_agent/Meltingpot_muliagent_env/meltingpot_repo/assets/saved_models/paintball__king_of_the_hill/free_bot_0"

NUM_EPISODES = 5
RENDER_SCALE = 4     # í™”ë©´ í™•ëŒ€ ë°°ìœ¨
FPS = 15             # ì˜ìƒ ì €ì¥ ë° ì¬ìƒ ì†ë„
VIDEO_DIR = "videos" # ì˜ìƒ ì €ì¥ í´ë”

# ==============================================================================
# 2. ì—ì´ì „íŠ¸ í´ë˜ìŠ¤ ì •ì˜
# ==============================================================================

class UserAgent:
    """
    RLlib Checkpointë¥¼ ì‚¬ìš©í•˜ëŠ” ì—ì´ì „íŠ¸
    - íŠ¹ì§•: í•™ìŠµ í™˜ê²½ê³¼ ë™ì¼í•˜ê²Œ FrameStack(4)ì„ ìˆ˜ë™ìœ¼ë¡œ ì ìš©
    """
    def __init__(self, algorithm, policy_id, device):
        self.algo = algorithm
        self.policy_id = policy_id
        self.device = device
        
        # Frame Stack ê´€ë¦¬ (í•™ìŠµ ì„¤ì •ê³¼ ë™ì¼í•˜ê²Œ 4í”„ë ˆì„)
        self.num_stack = 3
        self.frames = collections.deque(maxlen=self.num_stack)
        
        # ë‚´ë¶€ ìƒíƒœ (LSTM ë“± ì‚¬ìš© ì‹œ í•„ìš”, í˜„ì¬ ëª¨ë¸ì€ Statelessì§€ë§Œ í˜¸í™˜ì„± ìœ ì§€)
        self.state = [] 
        
        # ì´ˆê¸°í™”: ì •ì±…ì—ì„œ ì´ˆê¸° ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
        policy = self.algo.get_policy(self.policy_id)
        if policy:
            self.state = policy.get_initial_state()

    def reset(self, initial_obs):
        """ì—í”¼ì†Œë“œ ì‹œì‘ ì‹œ ìŠ¤íƒ ì´ˆê¸°í™”"""
        self.frames.clear()
        # ì´ˆê¸° í”„ë ˆì„ìœ¼ë¡œ ìŠ¤íƒ ì±„ìš°ê¸°
        processed = self._process_obs(initial_obs)
        for _ in range(self.num_stack):
            self.frames.append(processed)
            
        # ìƒíƒœ ì´ˆê¸°í™”
        policy = self.algo.get_policy(self.policy_id)
        self.state = policy.get_initial_state()
    
    def _process_obs(self, obs):
        """ì…ë ¥ê°’ ë³´ì • ë° RGB ì¶”ì¶œ"""
        if isinstance(obs, dict) and 'RGB' in obs:
            img = obs['RGB']
        else:
            img = obs
            
        # [í•µì‹¬] ë§Œì•½ ì´ë¯¸ì§€ê°€ float(0.0~1.0)ìœ¼ë¡œ ë“¤ì–´ì˜¤ë©´ 255ë¥¼ ê³±í•´ì„œ ë³µêµ¬í•´ì¤˜ì•¼ í•¨
        if img.dtype == np.float32 and img.max() <= 1.0:
            img = (img * 255).astype(np.uint8)
            
        return img

    def act(self, obs):
        """í–‰ë™ ê²°ì •"""
        # 1. í”„ë ˆì„ ìŠ¤íƒ ì—…ë°ì´íŠ¸
        current_frame = self._process_obs(obs)
        self.frames.append(current_frame)
        
        # 2. ìŠ¤íƒ ê²°í•© (Channel Concatenation) -> (88, 88, 12)
        # numpy stackì€ (4, 88, 88, 3) -> reshape or concatenate -> (88, 88, 12)
        # RLlib FrameStackWrapperì˜ ë°©ì‹: Concatenate along last axis
        stacked_obs = np.concatenate(list(self.frames), axis=-1)
        
        # 3. í–‰ë™ ì¶”ë¡  (compute_single_action)
        # full_fetch=Trueë¥¼ í•´ì•¼ state ê´€ë¦¬ê°€ ìš©ì´í•¨
        result = self.algo.compute_single_action(
            observation=stacked_obs,
            state=self.state,
            policy_id=self.policy_id,
            explore=True,  # í‰ê°€ ëª¨ë“œ (ê²°ì •ë¡ ì  í–‰ë™)
            full_fetch=True
        )
        
        # 4. ê²°ê³¼ ì–¸íŒ¨í‚¹
        if isinstance(result, tuple) and len(result) >= 3:
            action, state_out, _ = result
        else:
            action = result
            state_out = self.state

        self.state = state_out
        return action


class BotAgent:
    """
    Melting Pot ê³µì‹ SavedModelPolicyë¥¼ ì‚¬ìš©í•˜ëŠ” ë´‡
    """
    def __init__(self, model_path):
        if not os.path.exists(model_path):
            print(f"âŒ [BotAgent] ê²½ë¡œ ì—†ìŒ: {model_path}")
            sys.exit(1)
            
        self.policy = saved_model_policy.SavedModelPolicy(model_path)
        self.state = self.policy.initial_state()

    def reset(self):
        self.state = self.policy.initial_state()

    def act(self, obs):
        # Shimmy Dict Obs -> dm_env.TimeStep ë³€í™˜
        timestep = dm_env.TimeStep(
            step_type=dm_env.StepType.MID,
            reward=0.0,
            discount=1.0,
            observation=obs 
        )
        
        # ì •ì±… ì‹¤í–‰
        action, next_state = self.policy.step(timestep, self.state)
        self.state = next_state
        return int(action)

# ==============================================================================
# 3. ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# ==============================================================================
def main():
    # -------------------------------------------------------------------------
    # A. ì´ˆê¸°í™” (Ray, Model, Env)
    # -------------------------------------------------------------------------
    if not ray.is_initialized():
        ray.init(ignore_reinit_error=True)

    # Custom Model ë“±ë¡
    ModelCatalog.register_custom_model("meltingpot_model", MeltingPotModel)
    
    # Env ë“±ë¡ (Checkpoint ë¡œë”©ìš©, ì‹¤ì œ ì‹¤í–‰ì€ Raw Shimmy Env ì‚¬ìš©)
    env_name = "meltingpot_paintball_koth_mixed"
    register_env(env_name, lambda cfg: env_creator({"substrate": "paintball__king_of_the_hill"}))

    print(f"ğŸ”„ Checkpoint Loading: {USER_CHECKPOINT_PATH}")
    try:
        # RLlib ì•Œê³ ë¦¬ì¦˜ ë¡œë“œ
        user_algo = Algorithm.from_checkpoint(USER_CHECKPOINT_PATH)
    except Exception as e:
        print(f"âŒ Checkpoint ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # ì‹¤ì œ ê²Œì„ í™˜ê²½ ìƒì„± (Shimmy Raw Env - ë´‡ í˜¸í™˜ì„±ì„ ìœ„í•´ Wrapper ìµœì†Œí™”)
    # Botì€ Raw Dictë¥¼ ì›í•˜ê³ , UserëŠ” Stacked Arrayë¥¼ ì›í•˜ë¯€ë¡œ
    # í™˜ê²½ì€ Rawë¡œ ë‘ê³  UserAgent ë‚´ë¶€ì—ì„œ Stack ì²˜ë¦¬ë¥¼ í•©ë‹ˆë‹¤.
    env = shimmy.MeltingPotCompatibilityV0(
        substrate_name="paintball__king_of_the_hill",
        render_mode="rgb_array"
    )
    raw_env = env.par_env if hasattr(env, 'par_env') else env
    possible_agents = raw_env.possible_agents
    
    print(f"âœ… í™˜ê²½ ìƒì„± ì™„ë£Œ. Agents: {possible_agents}")
    
    # ì˜ìƒ ì €ì¥ í´ë” ìƒì„±
    os.makedirs(VIDEO_DIR, exist_ok=True)

    # -------------------------------------------------------------------------
    # B. ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    # -------------------------------------------------------------------------
    # Player 0, 2 (User) / Player 1, 3 (Bot)
    agents = {}
    device = "cuda" if torch.cuda.is_available() else "cpu"

    for agent_id in possible_agents:
        # agent_id format: "player_0", "player_1", ...
        idx = int(agent_id.split("_")[-1])
        
        if idx % 2 == 0: # ì§ìˆ˜: User (Red Team)
            print(f" -> {agent_id}: UserAgent (RLlib Main Policy)")
            # ì²´í¬í¬ì¸íŠ¸ ë‚´ ì •ì±… ì´ë¦„ ë§¤í•‘ (train.pyì˜ policy_mapping_fn ì°¸ì¡°)
            # ë³´í†µ 0,2ëŠ” 'main_policy'ë¡œ í›ˆë ¨ë¨
            agents[agent_id] = UserAgent(user_algo, "main_policy", device)
        else: # í™€ìˆ˜: Bot (Blue Team)
            print(f" -> {agent_id}: BotAgent (Official Policy)")
            agents[agent_id] = BotAgent(BOT_MODEL_DIR)

    # -------------------------------------------------------------------------
    # C. ì—í”¼ì†Œë“œ ë£¨í”„
    # -------------------------------------------------------------------------
    win_stats = {"User": 0, "Bot": 0, "Draw": 0}

    for ep in range(1, NUM_EPISODES + 1):
        print(f"\nğŸ¬ Episode {ep}/{NUM_EPISODES} Start...")
        
        obs, infos = env.reset()
        done = False
        step_count = 0
        
        # ì ìˆ˜ ì´ˆê¸°í™”
        ep_rewards = {aid: 0.0 for aid in possible_agents}
        
        # ì—ì´ì „íŠ¸ ìƒíƒœ ì´ˆê¸°í™”
        for aid, agent in agents.items():
            if isinstance(agent, UserAgent):
                agent.reset(obs[aid])
            elif isinstance(agent, BotAgent):
                agent.reset()

        # ë¹„ë””ì˜¤ ì„¤ì • (ì²« í”„ë ˆì„ ë Œë”ë§ í›„ í¬ê¸° ê²°ì •)
        video_writer = None
        video_path = os.path.join(VIDEO_DIR, f"ep_{ep:03d}_user_vs_bot.mp4")

        try:
            while not done:
                # 1. í–‰ë™ ê²°ì •
                actions = {}
                for agent_id in obs.keys():
                    if agent_id in agents:
                        act = agents[agent_id].act(obs[agent_id])
                        actions[agent_id] = act
                
                # 2. í™˜ê²½ ì§„í–‰
                next_obs, rewards, terminations, truncations, infos = env.step(actions)
                
                # 3. ë¦¬ì›Œë“œ ì§‘ê³„
                for aid, r in rewards.items():
                    ep_rewards[aid] += r
                
                # 4. ì¢…ë£Œ ì¡°ê±´
                if any(terminations.values()) or all(truncations.values()):
                    done = True
                
                obs = next_obs
                step_count += 1

                # 5. ë Œë”ë§ ë° ì˜ìƒ ì €ì¥
                frame = env.render() # (H, W, 3) RGB
                if frame is not None:
                    # RGB -> BGR (OpenCVìš©)
                    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    
                    # í™•ëŒ€
                    h, w, _ = frame_bgr.shape
                    frame_resized = cv2.resize(frame_bgr, (w * RENDER_SCALE, h * RENDER_SCALE), interpolation=cv2.INTER_NEAREST)
                    
                    # ì ìˆ˜ ì˜¤ë²„ë ˆì´
                    user_score = sum(ep_rewards[a] for a in possible_agents if int(a.split("_")[-1]) % 2 == 0)
                    bot_score = sum(ep_rewards[a] for a in possible_agents if int(a.split("_")[-1]) % 2 != 0)
                    
                    cv2.putText(frame_resized, f"Ep {ep} | Step {step_count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                    cv2.putText(frame_resized, f"User(Red): {user_score:.1f}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                    cv2.putText(frame_resized, f"Bot(Blue): {bot_score:.1f}", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

                    # í™”ë©´ í‘œì‹œ
                    cv2.imshow("User vs Bot", frame_resized)
                    if cv2.waitKey(1) & 0xFF == 27: # ESCë¡œ ì¤‘ë‹¨ ê°€ëŠ¥
                        print("User interrupted.")
                        env.close()
                        return

                    # ë¹„ë””ì˜¤ ì´ˆê¸°í™” (ìµœì´ˆ 1íšŒ)
                    if video_writer is None:
                        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                        video_writer = cv2.VideoWriter(video_path, fourcc, FPS, (frame_resized.shape[1], frame_resized.shape[0]))
                    
                    # í”„ë ˆì„ ì“°ê¸°
                    video_writer.write(frame_resized)

        finally:
            if video_writer:
                video_writer.release()
                print(f"   ğŸ’¾ Video saved: {video_path}")

        # ê²°ê³¼ ì§‘ê³„
        user_total = sum(ep_rewards[a] for a in possible_agents if int(a.split("_")[-1]) % 2 == 0)
        bot_total = sum(ep_rewards[a] for a in possible_agents if int(a.split("_")[-1]) % 2 != 0)
        
        print(f"ğŸ Episode {ep} Result: User {user_total:.1f} vs Bot {bot_total:.1f}")
        
        if user_total > bot_total:
            win_stats["User"] += 1
        elif bot_total > user_total:
            win_stats["Bot"] += 1
        else:
            win_stats["Draw"] += 1

    # -------------------------------------------------------------------------
    # D. ì¢…ë£Œ
    # -------------------------------------------------------------------------
    env.close()
    cv2.destroyAllWindows()
    ray.shutdown()
    
    print("\n" + "="*50)
    print(f"ğŸ“Š Final Stats (Total {NUM_EPISODES} Games)")
    print(f"   User Wins: {win_stats['User']}")
    print(f"   Bot Wins : {win_stats['Bot']}")
    print(f"   Draws    : {win_stats['Draw']}")
    print("="*50)

if __name__ == "__main__":
    main()